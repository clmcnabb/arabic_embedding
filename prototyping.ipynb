{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "import pandas as pd\n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"aubmindlab/bert-base-arabert\")\n",
    "embeddings_model = AutoModel.from_pretrained(\"aubmindlab/bert-base-arabert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"aubmindlab/bert-base-arabert\", num_labels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"New_News_Train.csv\")\n",
    "print(len(train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing embedding on one sample sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text: \n",
      "اشتباك الحريري عون اتهامات لباسيل بالتمسك بالثلث المعطل للبقاء الحكم\n"
     ]
    }
   ],
   "source": [
    "test_text = train_df['Removed_stopwords'][0]\n",
    "print(f'Sample text: \\n{test_text}')\n",
    "encoded = tokenizer.encode_plus(test_text, return_tensors='pt', padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([1, 28, 768])\n",
      "tensor([[[-0.4110,  0.5989,  0.0211,  ..., -0.1455,  0.5592, -0.0201],\n",
      "         [-0.5982,  0.1977,  0.0026,  ..., -0.6627,  0.3994,  0.3359],\n",
      "         [-1.3771,  0.8943,  0.9873,  ..., -0.9149,  0.8265, -0.2859],\n",
      "         ...,\n",
      "         [-1.3770,  0.8945,  0.9878,  ..., -0.9152,  0.8269, -0.2864],\n",
      "         [-0.8602, -0.0306,  0.1687,  ..., -0.3396,  0.6240, -0.7508],\n",
      "         [-0.7569,  0.1673, -0.0054,  ..., -0.2516,  0.3591, -0.5484]]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    embeddings_model_output = embeddings_model(**encoded)\n",
    "    embeddings = embeddings_model_output.last_hidden_state\n",
    "\n",
    "print(f'Shape: {embeddings.shape}')\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up for using full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AraBERTDataset(Dataset):\n",
    "    def __init__(self, file, tokenizer, model):\n",
    "        self.df = pd.read_csv(file)\n",
    "        self.data = self.df['Removed_stopwords'].values\n",
    "        self.labels = self.df['Type'].values\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.data[index]\n",
    "        label = self.labels[index]\n",
    "        encoded = self.tokenizer.encode_plus(text, return_tensors='pt', padding='max_length', truncation=True)\n",
    "        with torch.no_grad():\n",
    "            model_output = self.model(**encoded)\n",
    "            embeddings = model_output.last_hidden_state\n",
    "        return embeddings, label\n",
    "        # return {\n",
    "        #     'input_ids': encoded['input_ids'].flatten(),\n",
    "        #     'attention_mask': encoded['attention_mask'].flatten()\n",
    "        # }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = AraBERTDataset('New_News_Train.csv', tokenizer, embeddings_model)\n",
    "testing_data = AraBERTDataset('New_News_Test.csv', tokenizer, embeddings_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(testing_data, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.eval()\n",
    "model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 3.4742e-01,  2.5696e-01,  1.5328e-01,  ...,  3.3824e-01,\n",
      "            4.5029e-01,  2.7588e-01],\n",
      "          [ 7.8734e-02, -1.5832e-01,  3.3051e-01,  ...,  2.7933e-01,\n",
      "            6.8462e-01, -1.5104e-01],\n",
      "          [-3.1802e-01,  6.8979e-02,  5.0427e-01,  ..., -2.6783e-01,\n",
      "            5.9774e-01, -9.5489e-02],\n",
      "          ...,\n",
      "          [ 2.2355e-01, -1.7585e-01,  4.5014e-01,  ...,  3.6822e-01,\n",
      "            3.6171e-01, -5.6295e-02],\n",
      "          [ 1.1977e-01, -1.1467e-01,  3.8133e-01,  ...,  1.8485e-01,\n",
      "            5.7538e-01,  6.7956e-02],\n",
      "          [ 2.8141e-02,  1.2968e-02,  4.0619e-01,  ...,  8.8852e-02,\n",
      "            5.5666e-01, -4.7642e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.5427e-01,  5.3390e-01,  8.8916e-01,  ..., -3.0383e-01,\n",
      "            2.5848e-01,  9.1550e-01],\n",
      "          [-6.1077e-01,  9.7729e-02,  5.8500e-01,  ...,  1.7084e-02,\n",
      "           -2.9557e-01,  3.2185e-01],\n",
      "          [-1.0371e+00,  3.8980e-01,  1.5889e-01,  ..., -2.4177e-01,\n",
      "            1.2125e-01,  4.6174e-01],\n",
      "          ...,\n",
      "          [-7.4752e-01,  2.5926e-01,  2.5955e-01,  ..., -4.1796e-01,\n",
      "           -1.1652e-01,  1.6113e-01],\n",
      "          [-7.7261e-01, -2.7400e-02,  3.5770e-01,  ..., -2.2257e-01,\n",
      "           -1.9866e-01, -1.2539e-01],\n",
      "          [-4.5339e-01, -1.4402e-01,  3.7849e-01,  ..., -2.3462e-01,\n",
      "            2.0155e-01,  2.2559e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4129e-01,  8.4506e-01,  1.2053e-01,  ..., -1.9971e-01,\n",
      "            7.5636e-01,  5.4655e-01],\n",
      "          [ 9.2988e-02, -4.7872e-02,  6.7343e-02,  ..., -5.2095e-02,\n",
      "            6.1458e-01,  6.7179e-02],\n",
      "          [-7.9334e-01, -1.1844e-01,  7.4321e-01,  ..., -3.1046e-01,\n",
      "            8.8632e-01,  7.1260e-01],\n",
      "          ...,\n",
      "          [ 1.0381e-01,  3.5227e-02,  1.0193e-01,  ..., -1.9363e-01,\n",
      "            3.9592e-01,  1.8802e-02],\n",
      "          [-7.9291e-02, -6.2176e-02,  2.2156e-01,  ...,  7.3822e-02,\n",
      "            3.5680e-01, -2.0537e-01],\n",
      "          [ 7.0709e-02, -3.3792e-02,  2.8831e-01,  ...,  4.3510e-02,\n",
      "            5.4826e-01,  7.1138e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.5739e-01,  1.2565e-01, -5.1213e-01,  ...,  3.0221e-01,\n",
      "            5.6623e-01, -2.2761e-01],\n",
      "          [-4.4229e-01, -5.8785e-01,  4.1823e-01,  ...,  7.5956e-01,\n",
      "            7.2443e-01,  6.9357e-01],\n",
      "          [-5.5331e-01, -1.9719e-01, -3.1211e-01,  ..., -2.4080e-01,\n",
      "           -1.5160e-01,  2.8022e-01],\n",
      "          ...,\n",
      "          [ 1.9431e-01, -1.6537e-01,  1.9750e-01,  ...,  2.3736e-02,\n",
      "            1.1652e-01, -7.0514e-02],\n",
      "          [ 1.2082e-01, -1.8792e-01,  2.5899e-01,  ...,  2.0715e-01,\n",
      "           -2.7108e-01, -2.5013e-02],\n",
      "          [ 7.5146e-02, -1.4896e-01,  7.6317e-02,  ..., -8.5713e-02,\n",
      "            1.3428e-01, -5.9161e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5836e-02,  1.2796e-01,  6.1269e-01,  ..., -3.0491e-03,\n",
      "            5.6827e-01, -1.0516e-02],\n",
      "          [ 1.0384e-01, -1.6085e-01,  7.4476e-01,  ..., -8.1872e-01,\n",
      "           -3.7577e-01, -1.6238e-01],\n",
      "          [-5.9016e-01, -9.6358e-02,  1.5080e-01,  ..., -7.9845e-01,\n",
      "            5.1542e-02, -4.5814e-01],\n",
      "          ...,\n",
      "          [ 1.4249e-02,  3.4922e-03,  3.2935e-02,  ..., -6.1212e-01,\n",
      "            1.8809e-02,  2.6382e-01],\n",
      "          [ 5.4396e-03, -1.1798e-01, -7.8976e-02,  ..., -4.2990e-01,\n",
      "            5.1881e-02, -1.0376e-01],\n",
      "          [ 9.9942e-05, -1.1458e-01, -3.1198e-01,  ..., -5.4853e-01,\n",
      "           -6.9949e-02, -3.7516e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.2142e-02,  5.9687e-01,  2.8078e-01,  ...,  5.7363e-02,\n",
      "            7.6242e-01,  5.2338e-01],\n",
      "          [-5.9498e-01, -1.3089e-01, -1.1384e-02,  ..., -3.4280e-01,\n",
      "            2.2405e-02,  6.1179e-01],\n",
      "          [ 1.3750e-01,  3.5280e-02,  1.1747e-01,  ...,  1.8956e-01,\n",
      "            3.6774e-01,  1.4222e-01],\n",
      "          ...,\n",
      "          [-2.8364e-01, -3.1557e-01, -5.4578e-02,  ..., -3.7995e-01,\n",
      "           -6.3998e-02,  3.5745e-01],\n",
      "          [-1.1203e-01, -1.3663e-01, -1.6757e-01,  ..., -4.7778e-01,\n",
      "            1.5919e-01, -1.6025e-01],\n",
      "          [ 2.0279e-01, -6.2553e-02,  1.6470e-01,  ..., -4.3306e-01,\n",
      "            4.0369e-01, -1.0004e-02]]]])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 14\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/dev/upwork/arabic_embedding/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/upwork/arabic_embedding/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/upwork/arabic_embedding/.venv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1691\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1683\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1685\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1688\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1689\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1691\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1692\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1697\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1698\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1699\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1701\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1703\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1705\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[0;32m~/dev/upwork/arabic_embedding/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/upwork/arabic_embedding/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/upwork/arabic_embedding/.venv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1059\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to specify either input_ids or inputs_embeds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1059\u001b[0m batch_size, seq_length \u001b[38;5;241m=\u001b[39m input_shape\n\u001b[1;32m   1060\u001b[0m device \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;28;01mif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m inputs_embeds\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# past_key_values_length\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):  # Fine-tune for 5 epochs\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        inputs, labels = batch\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
